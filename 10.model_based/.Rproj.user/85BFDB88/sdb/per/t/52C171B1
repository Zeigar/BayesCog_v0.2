{
    "contents" : "# =============================================================================\n#### Info #### \n# =============================================================================\n# Hierachical simple reinforcement learning model\n#\n# true parameters: lr  = rnorm(10, mean=0.6, sd=0.12); tau = rnorm(10, mean=1.5, sd=0.2)\n#\n# Lei Zhang, UKE, Hamburg, DE\n# lei.zhang@uke.de\n\n# =============================================================================\n#### Construct Data #### \n# =============================================================================\n# clear workspace\nrm(list=ls(all=TRUE))\nlibrary(rstan)\nlibrary(ggplot2)\n\nload('_data/rl_mp.RData')\nsz <- dim(rl_mp)\nnSubjects <- sz[1]\nnTrials   <- sz[2]\n\ndataList <- list(nSubjects=nSubjects,\n                 nTrials=nTrials, \n                 choice=rl_mp[,,1], \n                 reward=rl_mp[,,2])\n\n\n# =============================================================================\n#### Running Stan #### \n# =============================================================================\nrstan_options(auto_write = TRUE)\noptions(mc.cores = 2)\n\nmodelFile <- '_scripts/reinforcement_learning_model_based.stan'\n\nnIter     <- 2000\nnChains   <- 4 \nnWarmup   <- floor(nIter/2)\nnThin     <- 1\n\ncat(\"Estimating\", modelFile, \"model... \\n\")\nstartTime = Sys.time(); print(startTime)\ncat(\"Calling\", nChains, \"simulations in Stan... \\n\")\n\nfit_rl <- stan(modelFile, \n               data    = dataList, \n               chains  = nChains,\n               iter    = nIter,\n               warmup  = nWarmup,\n               thin    = nThin,\n               init    = \"random\",\n               seed    = 1450154185\n)\n\ncat(\"Finishing\", modelFile, \"model simulation ... \\n\")\nendTime = Sys.time(); print(endTime)  \ncat(\"It took\",as.character.Date(endTime - startTime), \"\\n\")\n\nsaveRDS(fit_rl, file='_outputs/fit_rl.RData')\n\n# =============================================================================\n#### Model Summary, extract internal model variables #### \n# =============================================================================\nfit_rl <- readRDS('_outputs/fit_rl.RData')\n\nprint(fit_rl, pars = c('lr_mu', 'tau_mu', 'lr', 'tau', 'log_lik'))\n\ndec_var <- get_posterior_mean(fit_rl, pars=c('vc', 'pe', 'v'))[,5]\nvc <- dec_var[1:(nSubjects*nTrials)]\npe <- dec_var[(1:(nSubjects*nTrials)) + nSubjects*nTrials]\nvc <- matrix(vc, nrow = nSubjects, ncol = nTrials, byrow = T)\npe <- matrix(pe, nrow = nSubjects, ncol = nTrials, byrow = T)\n\n#### take one participants as an example, subj = 1\nvc_sub1 <- vc[1,]\npe_sub1 <- pe[1,]\nch_sub1 <- dataList$choice[1,]\nrw_sub1 <- dataList$reward[1,]\n\ndf_sub1 <- data.frame(trial  = 1:nTrials,\n                      choice = ch_sub1,\n                      reward = rw_sub1,\n                      value  = vc_sub1,\n                      pe     = pe_sub1)\n\n#### make plots of choice, reward, v(chn), and pe\nlibrary(ggplot2)\nmyconfig <- theme_bw(base_size = 20) +\n    theme(panel.grid.major = element_blank(),\n          panel.grid.minor = element_blank(),\n          panel.background = element_blank() )\n\ng1 <- ggplot(df_sub1, aes(x=trial, y=value)) \ng1 <- g1 + geom_line(size = 2, color = 'black') + geom_point(size = 3, shape = 21, fill='black')\ng1 <- g1 + myconfig + labs(x = 'Trial', y = 'Chosen Value')\ng1\n\ng2 <- ggplot(df_sub1, aes(x=trial, y=pe)) \ng2 <- g2 + geom_line(size = 2, color = 'black') + geom_point(size = 3, shape = 21, fill='black')\ng2 <- g2 + myconfig + labs(x = 'Trial', y = 'Prediction Error')\ng2\n\nggsave(plot = g1, \"_plots/sub1_value.png\", width = 10, height = 4, type = \"cairo-png\", units = \"in\")\nggsave(plot = g2, \"_plots/sub1_pe.png\", width = 10, height = 4, type = \"cairo-png\", units = \"in\")\n\n\n#### EXERCISE: extract and plot the value of option2 ####\nv <- dec_var[((nSubjects*nTrials)*2+1):length(dec_var)]\nv <- matrix(v, nrow = 2, ncol = length(v)/2) # 1st row for option1, 2nd row for option2\n\nv_op1 <- v[1,]\nv_op1 <- matrix(v_op1, nrow = nSubjects, ncol = nTrials+1, byrow = T)\nv_op1 <- v_op1[1:nSubjects, 1:nTrials]  # remove the 101th trial\nv_op1_sub1 <- v_op1[1,]\n\nv_op2 <- v[2,]\nv_op2 <- matrix(v_op2, nrow = nSubjects, ncol = nTrials+1, byrow = T)\nv_op2 <- v_op2[1:nSubjects, 1:nTrials]  # remove the 101th trial\nv_op2_sub1 <- v_op2[1,]\n\ndf2_sub1 <- data.frame(trial  = 1:nTrials,\n                       value1 = v_op1_sub1,\n                       value2 = v_op2_sub1)\n\ng3 <- ggplot(df2_sub1, aes(x=trial, y=value1)) \ng3 <- g3 + geom_line(size = 2, color = 'black') + geom_point(size = 3, shape = 21, fill='black')\ng3 <- g3 + myconfig + labs(x = 'Trial', y = 'value of option 1')\ng3\n\ng4 <- ggplot(df2_sub1, aes(x=trial, y=value2)) \ng4 <- g4 + geom_line(size = 2, color = 'black') + geom_point(size = 3, shape = 21, fill='black')\ng4 <- g4 + myconfig + labs(x = 'Trial', y = 'value of option 2')\ng4\n\nggsave(plot = g3, \"_plots/sub1_value_opt1.png\", width = 10, height = 4, type = \"cairo-png\", units = \"in\")\nggsave(plot = g4, \"_plots/sub1_value_opt2.png\", width = 10, height = 4, type = \"cairo-png\", units = \"in\")\n",
    "created" : 1476699866870.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2244176351",
    "id" : "52C171B1",
    "lastKnownWriteTime" : 1476230771,
    "path" : "E:/Dropbox/BayesCog/10.model_based/_scripts/reinforcement_learning_model_based_main_master.R",
    "project_path" : "_scripts/reinforcement_learning_model_based_main_master.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}